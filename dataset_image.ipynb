{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_fileImg(list_paths,batch_val=0,batch_test=0):\n",
    "    \n",
    "    labels=[]\n",
    "    label_names=[]\n",
    "    batch=2000\n",
    "    \n",
    "    image_files = tf.io.gfile.glob(list_paths)\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        if img_path.split('.')[1].split('/')[2] == \"cat\":\n",
    "            labels.append(1)\n",
    "            label_names.append(\"cat\")\n",
    "        else :\n",
    "            labels.append(0)\n",
    "            label_names.append(\"dog\")\n",
    "    \n",
    "    if batch_val > 0:\n",
    "        image_files = image_files[batch:batch+batch_val]\n",
    "        labels = labels[batch:batch+batch_val]\n",
    "        label_names[batch:batch+batch_val]\n",
    "    if batch_test > 0:\n",
    "        batch_val = 100\n",
    "        image_files = image_files[batch+batch_val:batch+batch_val+batch_test]\n",
    "        labels = labels[batch+batch_val:batch+batch_val+batch_test]\n",
    "        label_names[batch+batch_val:batch+batch_val+batch_test]\n",
    "    else:\n",
    "        image_files = image_files[:batch]\n",
    "        labels = labels[:batch]\n",
    "        label_names = label_names[:batch]\n",
    "            \n",
    "    return image_files,labels,label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img_data = tf.io.read_file(img_path)\n",
    "    feat = tf.image.decode_jpeg(img_data,channels=3)\n",
    "    feat = tf.image.convert_image_dtype(feat,tf.float32)\n",
    "    feat = tf.image.resize(feat,(128,128))\n",
    "    return feat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processus DataSet-TRAIN\n",
    "file_pattern = [\"./train/*.jpg\"]\n",
    "image_files,label_train,label_name_train = extract_fileImg(file_pattern)\n",
    "image_train = np.array([preprocess_image(i).numpy() for i in image_files])\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((image_train,tf.cast(label_train,tf.float32))).shuffle(2000).batch(500)\n",
    "dataset_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processus DataSet-VAL\n",
    "file_pattern = [\"./train/*.jpg\"]\n",
    "image_files,label_val,label_name_val = extract_fileImg(file_pattern,batch_val=100)\n",
    "image_val = np.array([preprocess_image(i).numpy() for i in image_files])\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((image_val,tf.cast(label_val,tf.float32))).shuffle(100).batch(100)\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processus DataSet-TEST\n",
    "file_pattern = [\"./train/*.jpg\"]\n",
    "image_files,label_test,label_name_test= extract_fileImg(file_pattern,batch_test=100)\n",
    "image_test = np.array([preprocess_image(i).numpy() for i in image_files])\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((image_test,tf.cast(label_test,tf.float32))).shuffle(100).batch(100)\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 61504)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                3936320   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 3,956,384\n",
      "Trainable params: 3,956,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "    #block 1\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu',padding='same',input_shape=(128,128,3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    #block 2\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    #Dense layers:\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(10,activation='relu'),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2,activation=\"softmax\")\n",
    "                                \n",
    "])\n",
    "\n",
    "model.compile(loss= tf.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=100, monitor='val_loss'), \n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='/home/malloc/logs/fit1', write_graph=True)\n",
    "           ]\n",
    "\n",
    "model.fit(dataset_train, epochs=5, callbacks=callbacks,validation_data=dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.evaluate(dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_predict = model.predict(dataset_test)\n",
    "size=24\n",
    "rows=8\n",
    "cols=4\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "for i,index in enumerate(np.random.choice(image_test.shape[0],size=size,replace=False)):\n",
    "    axis = fig.add_subplot(rows,cols,i+1,xticks=[],yticks=[])\n",
    "    axis.imshow(image_test[index])\n",
    "    index_p = np.argmax(y_predict[index])\n",
    "    index_t = int(label_test[index])\n",
    "    axis.set_title((\"{},({})\").format(label_name_test[index_p],label_name_test[index_p]), color=(\"green\" if index_p==index_t else \"red\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
